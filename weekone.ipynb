{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import BayesianRidge, ARDRegression\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import VotingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/week-one/\"\n",
    "train_filename, test_filename, macro_filename = \"X_train.csv\", \"X_test.csv\", \"macro.csv\"\n",
    "\n",
    "data = pd.read_csv(os.path.join(DATA_PATH, train_filename), parse_dates=['timestamp'])\n",
    "test = pd.read_csv(os.path.join(DATA_PATH, test_filename), parse_dates=['timestamp'])\n",
    "macro = pd.read_csv(os.path.join(DATA_PATH, macro_filename), parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21329, 292) (9142, 291) (2484, 100)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape, test.shape, macro.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful functions used for the preprocessing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce(data, threshold=0.9):\n",
    "    correlations = data.corr().abs()\n",
    "    upper = correlations.where(\n",
    "        np.triu(np.ones(correlations.shape), k=1).astype(np.bool))\n",
    "    to_drop = [\n",
    "        column for column in upper.columns if any(upper[column] > threshold)\n",
    "    ]\n",
    "    return data.drop(columns=to_drop)\n",
    "\n",
    "def inpute(data, feature, verbose=False, **kwargs):\n",
    "    X = data.copy().drop(columns=[feature])\n",
    "    X = X.select_dtypes(exclude=['object'])\n",
    "    X = X.fillna(X.median())\n",
    "    y = data[feature]\n",
    "    X_train = X[~y.isna()]\n",
    "    X_test = X[y.isna()]\n",
    "    y_train = y[~y.isna()]\n",
    "\n",
    "    model = DecisionTreeRegressor(**kwargs)\n",
    "    model.fit(X_train, y_train)\n",
    "    if verbose:\n",
    "        print(\"Feature: %s\" % feature)\n",
    "    filled_gaps = model.predict(X_test)\n",
    "    for i, ind in enumerate(data[feature][data[feature].isna()].index):\n",
    "        data.at[ind, feature] = filled_gaps[i]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate out target and features and exclude categorical features from training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add macro data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# macro = macro.fillna(macro.median())\n",
    "# X_all = pd.merge_ordered(data, macro, on='timestamp', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = data.copy()[\"price_doc\"]\n",
    "data.drop(['id', 'price_doc'], axis=1, inplace=True)\n",
    "# self.X = pd.merge_ordered(\n",
    "#     self.data.copy(), self.macro.copy(), on='timestamp', how='left')\n",
    "X = data.copy()\n",
    "# self.X.fillna(self.X.median(), inplace=True)\n",
    "\n",
    "# Take only numeric data for now\n",
    "X = X.select_dtypes(exclude=['object'])\n",
    "X.drop(columns=[\"timestamp\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce dimensionality by removing strongly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reduce(X, threshold=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add categorical features using one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some features would be best described with ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ecology'] = data['ecology'].map({'excellent':4,'good':3,'satisfactory':2,'poor':1,'no data':np.nan})\n",
    "X['ecology'] = data['ecology']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.select_dtypes(include=['object']).drop(columns=['sub_area', 'product_type']).columns:\n",
    "    data[column] = data[column].map({'yes':1, 'no':0})\n",
    "    X[column] = data[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X,pd.get_dummies(data.select_dtypes(include=['object']))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (21329, 321)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a basic decision tree regressor to predict missing values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for column in X.columns[X.isna().any() == True]:\n",
    "    X = inpute(X, column, min_samples_leaf=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (21329, 321)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = pd.DataFrame(dict([(column,abs(stats.zscore(X[column]))) for column in X.columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (21329, 321)\n"
     ]
    }
   ],
   "source": [
    "# X = X[~((z > 5).sum(axis=1) > 5)]\n",
    "print(\"Data shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weekone_models import models\n",
    "\n",
    "# models = {\n",
    "#     \"ridge\": {\n",
    "#         'model': sklearn.linear_model.Ridge(),\n",
    "#         'param_grid': {\n",
    "#             'ridge__alpha': np.logspace(2, 6, 10)\n",
    "#         }\n",
    "#     },\n",
    "#     # \"LinearRegression\": LinearRegression(),\n",
    "#     \"lasso\": {\n",
    "#         'model': sklearn.linear_model.Lasso(),\n",
    "#         'param_grid': {\n",
    "#             'lasso__alpha': np.logspace(-5, 1, 10)\n",
    "#         }\n",
    "#     },\n",
    "#     \"elasticnet\": {\n",
    "#         'model': sklearn.linear_model.ElasticNet(),\n",
    "#         'param_grid': {\n",
    "#             'elasticnet__alpha': np.logspace(-5, 1, 10)\n",
    "#         }\n",
    "#     },\n",
    "# #     \"linearsvr\": {\n",
    "# #         'model': sklearn.svm.LinearSVR(),\n",
    "# #         'param_grid': {\n",
    "# #             'linearsvr__C': np.logspace(-5, 0, 5)\n",
    "# #         }\n",
    "# #     },\n",
    "#     # \"BayesianRidge\": BayesianRidge(),\n",
    "#     # # \"ARDRegression\": ARDRegression(),\n",
    "#     # \"NuSVR\": NuSVR(),\n",
    "#     # # \"KernelRidge\": KernelRidge(),\n",
    "#     # # \"GaussianProcessRegressor\": GaussianProcessRegressor(),\n",
    "#     \"decisiontreeregressor\": {\n",
    "#         'model': DecisionTreeRegressor(),\n",
    "#         'param_grid' : {\n",
    "#             'decisiontreeregressor__max_depth': np.logspace(0, 1.3, 10, dtype=int),\n",
    "#             'decisiontreeregressor__min_samples_leaf': np.logspace(2, 3, 5, dtype=int)\n",
    "#         }\n",
    "#     },\n",
    "#     \"adaboostregressor\": {\n",
    "#         'model': sklearn.ensemble.AdaBoostRegressor(DecisionTreeRegressor(max_depth=3)),\n",
    "#         'param_grid': {\n",
    "#             'adaboostregressor__n_estimators': np.logspace(0, 3, 10, dtype=int)\n",
    "#         }\n",
    "#     },\n",
    "# #     \"mlpregressor\": {\n",
    "# #         'model': MLPRegressor(),\n",
    "# #         'param_grid': {\n",
    "# #             'mlpregressor__alpha': np.logspace(-5,-1,10)\n",
    "# #         }\n",
    "# #     }\n",
    "#     # \"PassiveAggressiveRegressor\": PassiveAggressiveRegressor()\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing search for ridge model\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   10.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing search for lasso model\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.4min finished\n",
      "/home/dmonk/miniconda3/envs/ml/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1726.0302716307956, tolerance: 0.7678317675400766\n",
      "  positive)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing search for elasticnet model\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e0b4b4656d03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best_index_'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     )\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mgscv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'best_estimator'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgscv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'best_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgscv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(\"Performing search for %s model\" % model)\n",
    "    pipeline = make_pipeline(StandardScaler(), models[model]['model'])\n",
    "\n",
    "    param_grid = models[model]['param_grid']\n",
    "\n",
    "    gscv = RandomizedSearchCV(\n",
    "        pipeline, param_grid, n_jobs=-1,\n",
    "        scoring='neg_root_mean_squared_error', verbose=1, cv=5,\n",
    "        refit='best_index_'\n",
    "    )\n",
    "    gscv.fit(X, np.log1p(y.loc[X.index]))\n",
    "    models[model]['best_estimator'] = gscv.best_estimator_\n",
    "    models[model]['best_score'] = gscv.best_score_\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    VotingRegressor(\n",
    "        estimators=[(model, models[model]['best_estimator'].steps[1][1]) for model in models] + [],\n",
    "        weights=[1/abs(models[model]['best_score']) for model in models],\n",
    "        n_jobs=-1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('votingregressor',\n",
       "                 VotingRegressor(estimators=[('ridge',\n",
       "                                              Ridge(alpha=46415.888336127726,\n",
       "                                                    copy_X=True,\n",
       "                                                    fit_intercept=True,\n",
       "                                                    max_iter=None,\n",
       "                                                    normalize=False,\n",
       "                                                    random_state=None,\n",
       "                                                    solver='auto', tol=0.001)),\n",
       "                                             ('lasso',\n",
       "                                              Lasso(alpha=4.641588833612782e-05,\n",
       "                                                    copy_X=True,\n",
       "                                                    f...\n",
       "                                                                                                     min_impurity_decrease=0.0,\n",
       "                                                                                                     min_impurity_split=None,\n",
       "                                                                                                     min_samples_leaf=1,\n",
       "                                                                                                     min_samples_split=2,\n",
       "                                                                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                                                                     presort='deprecated',\n",
       "                                                                                                     random_state=None,\n",
       "                                                                                                     splitter='best'),\n",
       "                                                                learning_rate=1.0,\n",
       "                                                                loss='linear',\n",
       "                                                                n_estimators=2,\n",
       "                                                                random_state=None))],\n",
       "                                 n_jobs=-1,\n",
       "                                 weights=[1.8426395237300688,\n",
       "                                          1.7699897548834416,\n",
       "                                          1.7699646046342574,\n",
       "                                          2.0428118024236523,\n",
       "                                          1.9680382174089224]))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('votingregressor',\n",
       "                 VotingRegressor(estimators=[('ridge',\n",
       "                                              Ridge(alpha=46415.888336127726,\n",
       "                                                    copy_X=True,\n",
       "                                                    fit_intercept=True,\n",
       "                                                    max_iter=None,\n",
       "                                                    normalize=False,\n",
       "                                                    random_state=None,\n",
       "                                                    solver='auto', tol=0.001)),\n",
       "                                             ('lasso',\n",
       "                                              Lasso(alpha=4.641588833612782e-05,\n",
       "                                                    copy_X=True,\n",
       "                                                    f...\n",
       "                                                                                                     min_impurity_decrease=0.0,\n",
       "                                                                                                     min_impurity_split=None,\n",
       "                                                                                                     min_samples_leaf=1,\n",
       "                                                                                                     min_samples_split=2,\n",
       "                                                                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                                                                     presort='deprecated',\n",
       "                                                                                                     random_state=None,\n",
       "                                                                                                     splitter='best'),\n",
       "                                                                learning_rate=1.0,\n",
       "                                                                loss='linear',\n",
       "                                                                n_estimators=2,\n",
       "                                                                random_state=None))],\n",
       "                                 n_jobs=-1,\n",
       "                                 weights=[1.8426395237300688,\n",
       "                                          1.7699897548834416,\n",
       "                                          1.7699646046342574,\n",
       "                                          2.0428118024236523,\n",
       "                                          1.9680382174089224]))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,np.log1p(y.loc[X.index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Ridge(alpha=46415.888336127726, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "       normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       " Lasso(alpha=4.641588833612782e-05, copy_X=True, fit_intercept=True,\n",
       "       max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "       random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       " ElasticNet(alpha=4.641588833612782e-05, copy_X=True, fit_intercept=True,\n",
       "            l1_ratio=0.5, max_iter=1000, normalize=False, positive=False,\n",
       "            precompute=False, random_state=None, selection='cyclic', tol=0.0001,\n",
       "            warm_start=False),\n",
       " DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=7,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=100, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best'),\n",
       " AdaBoostRegressor(base_estimator=DecisionTreeRegressor(ccp_alpha=0.0,\n",
       "                                                        criterion='mse',\n",
       "                                                        max_depth=3,\n",
       "                                                        max_features=None,\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=1,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        presort='deprecated',\n",
       "                                                        random_state=None,\n",
       "                                                        splitter='best'),\n",
       "                   learning_rate=1.0, loss='linear', n_estimators=2,\n",
       "                   random_state=None)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.steps[1][1].estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47701906241468833"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(\n",
    "    model.predict(X),\n",
    "    np.log1p(y.loc[X.index]),\n",
    "    squared=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['ecology'] = test['ecology'].map({'excellent':4,'good':3,'satisfactory':2,'poor':1,'no data':np.nan})\n",
    "for column in test.select_dtypes(include=['object']).drop(columns=['sub_area', 'product_type']).columns:\n",
    "    test[column] = test[column].map({'yes':1, 'no':0})\n",
    "X_predict = pd.concat([test.copy(),pd.get_dummies(test.select_dtypes(include=['object']))], axis=1)\n",
    "for column in X.columns:\n",
    "    if column not in X_predict:\n",
    "        X_predict[column] = 0\n",
    "X_predict = X_predict[X.columns]\n",
    "for column in X_predict.columns[X_predict.isna().any() == True]:\n",
    "    X_predict = inpute(X_predict, column, min_samples_leaf=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.expm1(model.predict(X_predict))\n",
    "predictions = pd.DataFrame(predictions, columns=[\"price_doc\"])\n",
    "predictions = pd.concat([test['id'], predictions], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv(os.path.join(DATA_PATH, \"predictions.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro = macro.fillna(macro.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = pd.merge_ordered(data, macro, on='timestamp', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(GradientBoostingRegressor(), {'alpha' :[0.8,0.9]}, n_jobs=-1)\n",
    "gscv = RandomizedSearchCV(\n",
    "        GradientBoostingRegressor(), {'alpha' :[0.8,0.9]}, n_jobs=-1,\n",
    "        scoring='neg_root_mean_squared_error', verbose=1, cv=5,\n",
    "        refit='best_index_'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmonk/miniconda3/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:  1.7min remaining:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  2.6min finished\n"
     ]
    }
   ],
   "source": [
    "gscv.fit(X,np.log1p(y.loc[X.index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.446725374234969"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(\n",
    "    model.predict(X),\n",
    "    np.log1p(y.loc[X.index]),\n",
    "    squared=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.expm1(model.predict(X_predict))\n",
    "predictions = pd.DataFrame(predictions, columns=[\"price_doc\"])\n",
    "predictions = pd.concat([test['id'], predictions], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv(os.path.join(DATA_PATH, \"predictions.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
