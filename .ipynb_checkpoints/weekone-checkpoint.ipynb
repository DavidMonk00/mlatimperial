{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import BayesianRidge, ARDRegression\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import VotingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/week-one/\"\n",
    "train_filename, test_filename, macro_filename = \"X_train.csv\", \"X_test.csv\", \"macro.csv\"\n",
    "\n",
    "data = pd.read_csv(os.path.join(DATA_PATH, train_filename), parse_dates=['timestamp'])\n",
    "test = pd.read_csv(os.path.join(DATA_PATH, test_filename), parse_dates=['timestamp'])\n",
    "macro = pd.read_csv(os.path.join(DATA_PATH, macro_filename), parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21329, 292) (9142, 291) (2484, 100)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape, test.shape, macro.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful functions used for the preprocessing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce(data, threshold=0.9):\n",
    "    correlations = data.corr().abs()\n",
    "    upper = correlations.where(\n",
    "        np.triu(np.ones(correlations.shape), k=1).astype(np.bool))\n",
    "    to_drop = [\n",
    "        column for column in upper.columns if any(upper[column] > threshold)\n",
    "    ]\n",
    "    return data.drop(columns=to_drop)\n",
    "\n",
    "def inpute(data, feature, verbose=False, **kwargs):\n",
    "    X = data.copy().drop(columns=[feature])\n",
    "    X = X.select_dtypes(exclude=['object'])\n",
    "    X = X.fillna(X.median())\n",
    "    y = data[feature]\n",
    "    X_train = X[~y.isna()]\n",
    "    X_test = X[y.isna()]\n",
    "    y_train = y[~y.isna()]\n",
    "\n",
    "    model = DecisionTreeRegressor(**kwargs)\n",
    "    model.fit(X_train, y_train)\n",
    "    if verbose:\n",
    "        print(\"Feature: %s\" % feature)\n",
    "    filled_gaps = model.predict(X_test)\n",
    "    for i, ind in enumerate(data[feature][data[feature].isna()].index):\n",
    "        data.at[ind, feature] = filled_gaps[i]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate out target and features and exclude categorical features from training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = data.copy()[\"price_doc\"]\n",
    "data.drop(['id', 'price_doc'], axis=1, inplace=True)\n",
    "# self.X = pd.merge_ordered(\n",
    "#     self.data.copy(), self.macro.copy(), on='timestamp', how='left')\n",
    "X = data.copy()\n",
    "# self.X.fillna(self.X.median(), inplace=True)\n",
    "\n",
    "# Take only numeric data for now\n",
    "X = X.select_dtypes(exclude=['object'])\n",
    "X.drop(columns=[\"timestamp\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce dimensionality by removing strongly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reduce(X, threshold=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a basic decision tree regressor to predict missing values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for column in X.columns[X.isna().any() == True]:\n",
    "    X = inpute(X, column, min_samples_leaf=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (21329, 161)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "#     \"ridge\": {\n",
    "#         'model': sklearn.linear_model.Ridge(),\n",
    "#         'param_grid': {\n",
    "#             'ridge__alpha': np.logspace(2, 6, 20)\n",
    "#         }\n",
    "#     },\n",
    "#     # \"LinearRegression\": LinearRegression(),\n",
    "#     \"lasso\": {\n",
    "#         'model': sklearn.linear_model.Lasso(),\n",
    "#         'param_grid': {\n",
    "#             'lasso__alpha': np.logspace(-5, 1, 20)\n",
    "#         }\n",
    "#     },\n",
    "#     \"elasticnet\": {\n",
    "#         'model': sklearn.linear_model.ElasticNet(),\n",
    "#         'param_grid': {\n",
    "#             'elasticnet__alpha': np.logspace(-5, 1, 20)\n",
    "#         }\n",
    "#     },\n",
    "#     \"linearsvr\": {\n",
    "#         'model': sklearn.svm.LinearSVR(),\n",
    "#         'param_grid': {\n",
    "#             'linearsvr__C': np.logspace(-5, 0, 10)\n",
    "#         }\n",
    "#     },\n",
    "    # \"BayesianRidge\": BayesianRidge(),\n",
    "    # # \"ARDRegression\": ARDRegression(),\n",
    "    # \"NuSVR\": NuSVR(),\n",
    "    # # \"KernelRidge\": KernelRidge(),\n",
    "    # # \"GaussianProcessRegressor\": GaussianProcessRegressor(),\n",
    "    \"DecisionTreeRegressor\": {\n",
    "        'model': DecisionTreeRegressor(),\n",
    "        'param_grid' : {\n",
    "            'decisiontreeregressor': {\n",
    "                'decisiontreeregressor__max_depth': np.logspace(0, 2, 20, dtype=int)\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    # # \"MLPRegressor\": MLPRegressor(),\n",
    "    # \"PassiveAggressiveRegressor\": PassiveAggressiveRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing search for ridge model\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   13.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing search for lasso model\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing search for elasticnet model\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing search for linearsvr model\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ridge': {'model': Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "        normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "  'param_grid': {'ridge__alpha': array([1.00000000e+02, 1.62377674e+02, 2.63665090e+02, 4.28133240e+02,\n",
       "          6.95192796e+02, 1.12883789e+03, 1.83298071e+03, 2.97635144e+03,\n",
       "          4.83293024e+03, 7.84759970e+03, 1.27427499e+04, 2.06913808e+04,\n",
       "          3.35981829e+04, 5.45559478e+04, 8.85866790e+04, 1.43844989e+05,\n",
       "          2.33572147e+05, 3.79269019e+05, 6.15848211e+05, 1.00000000e+06])},\n",
       "  'best_estimator': Pipeline(memory=None,\n",
       "           steps=[('standardscaler',\n",
       "                   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                  ('ridge',\n",
       "                   Ridge(alpha=33598.18286283781, copy_X=True, fit_intercept=True,\n",
       "                         max_iter=None, normalize=False, random_state=None,\n",
       "                         solver='auto', tol=0.001))],\n",
       "           verbose=False),\n",
       "  'best_score': -0.5524711612209755},\n",
       " 'lasso': {'model': Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "        normalize=False, positive=False, precompute=False, random_state=None,\n",
       "        selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  'param_grid': {'lasso__alpha': array([1.00000000e-05, 2.06913808e-05, 4.28133240e-05, 8.85866790e-05,\n",
       "          1.83298071e-04, 3.79269019e-04, 7.84759970e-04, 1.62377674e-03,\n",
       "          3.35981829e-03, 6.95192796e-03, 1.43844989e-02, 2.97635144e-02,\n",
       "          6.15848211e-02, 1.27427499e-01, 2.63665090e-01, 5.45559478e-01,\n",
       "          1.12883789e+00, 2.33572147e+00, 4.83293024e+00, 1.00000000e+01])},\n",
       "  'best_estimator': Pipeline(memory=None,\n",
       "           steps=[('standardscaler',\n",
       "                   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                  ('lasso',\n",
       "                   Lasso(alpha=0.1274274985703132, copy_X=True,\n",
       "                         fit_intercept=True, max_iter=1000, normalize=False,\n",
       "                         positive=False, precompute=False, random_state=None,\n",
       "                         selection='cyclic', tol=0.0001, warm_start=False))],\n",
       "           verbose=False),\n",
       "  'best_score': -0.5835306770014658},\n",
       " 'elasticnet': {'model': ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "             max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "             random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "  'param_grid': {'elasticnet__alpha': array([1.00000000e-05, 2.06913808e-05, 4.28133240e-05, 8.85866790e-05,\n",
       "          1.83298071e-04, 3.79269019e-04, 7.84759970e-04, 1.62377674e-03,\n",
       "          3.35981829e-03, 6.95192796e-03, 1.43844989e-02, 2.97635144e-02,\n",
       "          6.15848211e-02, 1.27427499e-01, 2.63665090e-01, 5.45559478e-01,\n",
       "          1.12883789e+00, 2.33572147e+00, 4.83293024e+00, 1.00000000e+01])},\n",
       "  'best_estimator': Pipeline(memory=None,\n",
       "           steps=[('standardscaler',\n",
       "                   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                  ('elasticnet',\n",
       "                   ElasticNet(alpha=0.26366508987303555, copy_X=True,\n",
       "                              fit_intercept=True, l1_ratio=0.5, max_iter=1000,\n",
       "                              normalize=False, positive=False, precompute=False,\n",
       "                              random_state=None, selection='cyclic', tol=0.0001,\n",
       "                              warm_start=False))],\n",
       "           verbose=False),\n",
       "  'best_score': -0.5819444113790205},\n",
       " 'linearsvr': {'model': LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "            intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "            random_state=None, tol=0.0001, verbose=0),\n",
       "  'param_grid': {'linearsvr__C': array([1.00000000e-03, 4.64158883e-03, 2.15443469e-02, 1.00000000e-01,\n",
       "          4.64158883e-01, 2.15443469e+00, 1.00000000e+01, 4.64158883e+01,\n",
       "          2.15443469e+02, 1.00000000e+03])},\n",
       "  'best_estimator': Pipeline(memory=None,\n",
       "           steps=[('standardscaler',\n",
       "                   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                  ('linearsvr',\n",
       "                   LinearSVR(C=0.004641588833612777, dual=True, epsilon=0.0,\n",
       "                             fit_intercept=True, intercept_scaling=1.0,\n",
       "                             loss='epsilon_insensitive', max_iter=1000,\n",
       "                             random_state=None, tol=0.0001, verbose=0))],\n",
       "           verbose=False),\n",
       "  'best_score': -0.6425795268715075}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(\"Performing search for %s model\" % model)\n",
    "    pipeline = make_pipeline(StandardScaler(), models[model]['model'])\n",
    "\n",
    "    param_grid = models[model]['param_grid']\n",
    "\n",
    "    gscv = GridSearchCV(\n",
    "        pipeline, param_grid, n_jobs=-1,\n",
    "        scoring='neg_root_mean_squared_error', verbose=1, cv=5,\n",
    "        refit='best_index_'\n",
    "    )\n",
    "    gscv.fit(X, np.log1p(y))\n",
    "    models[model]['best_estimator'] = gscv.best_estimator_\n",
    "    models[model]['best_score'] = gscv.best_score_\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
